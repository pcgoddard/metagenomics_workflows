'''
Long read assembly and post-processing Snakemake workflow
for assembling genomes from metagenomes.

Eli Moss
'''

import os
localrules: pilon_ranges, pilon_aggregate_vcf, assemble_final, faidx, extract_bigtigs, circularize_final

sample = config['sample_name']
fast5_dirs = [l.strip() for l in open(config['fast5_dirs_list'], 'r').readlines()]
fast5_abspath_run_subfolder = {}
fast5_run_subfolder_abspath = {}

singularity_image = config['singularity']

for d in fast5_dirs:
	run_subfolder = "/".join([d.split("/")[::-1][2], d.split("/")[::-1][0]])
	fast5_abspath_run_subfolder[run_subfolder] = d
	fast5_run_subfolder_abspath[d] = run_subfolder


#BUG: due to a problem with having multiple dynamic wildcards, the second output in rule all must be commented out until after the first has been generated.
rule all:
	input:
		"{sample}/2.polish/{sample}_polished.fa".format(sample = sample),
		"{sample}/4.final/{sample}_final.fa".format(sample = sample), #this must be commented out until after the workflow has reached the first output
		'{sample}/0.basecall/nanoplots/Weighted_LogTransformed_HistogramReadlength.png'.format(sample = sample)
#Basecalling and assembly
#########################################################

rule basecall:
	input: lambda wildcards: fast5_abspath_run_subfolder["/".join([wildcards.run, wildcards.subfolder])]
	output: '{sample}/0.basecall/raw_calls/{run}/{subfolder}/sequencing_summary.txt'
	threads: 4
	resources:
		time=2,
		mem=16
	singularity: singularity_image
	shell:
		"guppy_basecaller --cpu_threads_per_caller {threads} -i {input} -s {sample}/0.basecall/raw_calls/{wildcards.run}/{wildcards.subfolder}/ " +
		"--flowcell {fc} --kit {k}" .format(fc=config['flowcell'], k = config['kit'])

rule basecall_final:
	input: expand('{{sample}}/0.basecall/raw_calls/{foo}/sequencing_summary.txt', foo = fast5_abspath_run_subfolder.keys())
	output: '{sample}/0.basecall/{sample}.fq'
	shell:
		"find {sample}/0.basecall/raw_calls/*/*/*.fastq | xargs cat > {output}"

rule nanoplot:
	input: rules.basecall_final.output
	output: '{sample}/0.basecall/nanoplots/Weighted_LogTransformed_HistogramReadlength.png'
	resources:
		time=4
	threads: 12
	singularity: singularity_image
	shell: "NanoPlot --fastq {input} -t {threads} --color green  -o " + "{s}/0.basecall/nanoplots".format(s = sample)

rule assemble:
	input: rules.basecall_final.output
	output:
		'{sample}/1.assemble/assemble_{genome_size}/{sample}_{genome_size}.contigs.fasta',
		'{sample}/1.assemble/assemble_{genome_size}/{sample}_{genome_size}.correctedReads.fasta.gz'
	threads: 1
	resources:
		mem=100,
		time=80
	singularity: singularity_image if config['usegrid'] != 'True' and config['usegrid'] != True else '' #switch between image and local environment for canu depending on whether cluster execution is required
	shell:
		"canu -p {sample}_{wildcards.genome_size} -d {sample}/1.assemble/assemble_{wildcards.genome_size}/ -nanopore-raw {input} " +
		config['canu_args'] +
		" stopOnReadQuality=false genomeSize={wildcards.genome_size} " +
		"useGrid={grid} gridOptions='{opts}'".format(
			grid = config['usegrid'],
			opts = config['grid_options']
		)

rule merge:
	input: expand("{{sample}}/1.assemble/assemble_{g}/{{sample}}_{g}.contigs.fasta", g = config['genome_size'].split(","))
	output: "{sample}/1.assemble/{sample}_merged.fasta"
	resources:
		time=6,
		mem=24
	singularity: singularity_image
	shell:
		"merge_wrapper.py {input} -pre {sample}/1.assemble/{sample}_merged; mv merged.fasta {output}"

rule assemble_final:
	input: rules.merge.output
	output: '{sample}/1.assemble/{sample}_merged_cleaned.fa' #'{sample}/2.circlator/06.fixstart_cleannames.fasta' # #
	shell:
		"cat {input} | cut -f1 -d '_' | fold -w 120 | awk '(/^>/ && s[$0]++){{$0=$0\"_\"s[$0]}}1;' > {output}" #sed 's/\.tig/\\ttig/g' | tr '_' '\\t' | " +
		#"cut -f1,9,17 | tr '\\t' '_'

#Polishing
#########################################################

def choose_pilon_or_medaka():
	if config['short_reads'] != '':
		return(rules.pilon_consensus.output)
	else:
		return(rules.medaka.output)

rule medaka:
	input:
		rules.basecall_final.output,
		rules.assemble_final.output
	output: '{sample}/2.polish/medaka/consensus.fasta'
	threads: 16
	resources:
		mem=32,
		time=100
	singularity: singularity_image
	shell:
		'medaka_consensus -i {input[0]} -d {input[1]} -o {sample}/2.polish/medaka -t {threads} -m r941_flip213;'

		#'export VIRTUAL_ENV_DISABLE_PROMPT=1; source /labs/asbhatt/moss/tools/long_read/medaka-0.3.0/venv/bin/activate; ' ++
		#'deactivate'

rule align_short_reads:
	input:
		rules.assemble_final.output,
		config['short_reads'].split(',')
	output: "{sample}/2.polish/medaka/short_reads.bam"
	threads: 24
	params:
		reads = config['short_reads'].split(',')
	resources:
		mem=48,
		time=24
	singularity: singularity_image
	shell:
		"bwa index {input[0]}; bwa mem -t {threads} {input[0]} {params.reads} | samtools sort --threads {threads} > {output}"

rule pilon_ranges:
	input:
		rules.assemble_final.output,
		rules.assemble_final.output[0] + '.fai'
	output: dynamic('{sample}/2.polish/pilon/ranges/{range}')
	singularity: singularity_image
	shell:
		"""
		bedtools makewindows -w 100000 -g {input[1]} | awk '{{print $1,\":\", $2+ 1, \"-\", $3}}'  | tr -d ' ' |
		xargs -n 1 -I foo touch {sample}/2.polish/pilon/ranges/foo
		"""

rule pilon_subsetrun:
	input:
		rules.assemble_final.output,
		rules.align_short_reads.output,
		rules.align_short_reads.output[0] + '.bai',
		'{sample}/2.polish/pilon/ranges/{range}',
	output:
		'{sample}/2.polish/pilon/sub_runs/{range}/{sample}_{range}.vcf.gz'
	resources:
		time=lambda wildcards, attempt: 4 * attempt,
		mem=lambda wildcards, attempt: 32 * attempt
	singularity: singularity_image
	params:
		java_mem = 30,
		bam = "{sample}/2.polish/pilon/sub_runs/{range}/{sample}_{range}.bam",
		fa = "{sample}/2.polish/pilon/sub_runs/{range}/{sample}_{range}.fa",
		subrun_folder = "{sample}/2.polish/pilon/sub_runs/{range}"
	shell:
		"""
		# set env var $i to be the smallest read subset decimal (in increments of 0.1, with a couple very low values thrown in, too)
    	# sufficient to generate at least 40x coverage depth of the target sequence, or
		# 1 if 40x coverage cannot be achieved with the available read data

		for i in 0.01 0.05 $(seq 0.1 0.1 1);
		do
		   cov=$(samtools view {input[1]} -s $i -h {wildcards.range} | samtools depth - | cut -f3 | awk '{{sum+=$1}}END{{print sum/(NR+1)}}')
		   if [ $(echo $cov'>'50|bc) -eq 1 ]
		   then
		       break
		   fi
		done
		echo Using $i x of total coverage;

		samtools view -h -O BAM -s $i {input[1]} {wildcards.range} > {params.bam}
		samtools index {params.bam}
		samtools faidx {input[0]} $(echo {wildcards.range}| cut -f1 -d ':') | cut -f1 -d ':' > {params.fa}
		java -Xmx{params.java_mem}G -jar $(which pilon | sed 's/\/pilon//g')/../share/pilon*/pilon*.jar \
			--genome {params.fa} \
			--unpaired {params.bam} --output {sample}_{wildcards.range} --outdir {params.subrun_folder} \
			--vcf --nostrays
		bgzip {params.subrun_folder}/{sample}_{wildcards.range}.vcf
		tabix -fp vcf {params.subrun_folder}/{sample}_{wildcards.range}.vcf.gz
		"""

rule pilon_aggregate_vcf:
	input:
		dynamic(rules.pilon_subsetrun.output)
	output: '{sample}/2.polish/pilon/all_corrections.vcf.gz'
	resources:
		time=4,
		mem=8
	singularity: singularity_image
	shell:
		"""
		#get header
		(bcftools concat --naive {sample}/2.polish/pilon/sub_runs/*/*.vcf.gz | zcat | head -100000 | grep ^# || true

		#get corrections
		bcftools concat --naive {sample}/2.polish/pilon/sub_runs/*/*.vcf.gz | zcat | grep -v ^# | grep -v '0/0' | sort -u -k1,1d -k2,2g | grep -v SVTYPE) |

		#compress and store
		bgzip > {output}

		#index
		tabix -p vcf {output}
		"""

rule pilon_consensus:
	input:
		rules.assemble_final.output,
		rules.pilon_aggregate_vcf.output
	output:
		"{sample}/2.polish/pilon/{sample}_pilon.fa"
	singularity: singularity_image
	shell:
		"""
		bcftools consensus -f {input} -o {output} && rm -rf {sample}/2.polish/pilon/sub_runs {sample}/2.polish/pilon/ranges
		"""

rule polish_final:
	input: choose_pilon_or_medaka()
	output: "{sample}/2.polish/{sample}_polished.fa"
	shell:
		"""
		cp {input} {output}
		"""

#Circularization
#########################################################

def skip_circularization_or_not():
	if config['skip_circularization'] == 'True' or config['skip_circularization'] == True:
		return(rules.polish_final.output)
	else:
		return(rules.circularize_final.output)

rule circularize_mapreads:
	input:
		rules.polish_final.output,
		'{sample}/1.assemble/assemble_{g}/{sample}_{g}.correctedReads.fasta.gz'.format(
			g = config['genome_size'].split(",")[0],
			sample = sample)
	output:
		"{sample}/3.circularization/0.aligned_corrected.bam",
		"{sample}/3.circularization/0.aligned_corrected.bam.bai",
	threads: 8
	resources:
		time=6,
		mem=32
	singularity: singularity_image
	shell:
		"""
		minimap2 {input} -ax map-ont -t {threads} | samtools sort --threads {threads} > {output[0]}
		samtools index {output[0]}
		"""

rule extract_bigtigs:
	input:
		rules.polish_final.output,
		rules.polish_final.output[0] + ".fai",
	output: dynamic("{sample}/3.circularization/1.candidate_genomes/{tig}.fa")
	singularity: singularity_image
	params:
		min_size = 2000000
	shell:
		"""
		cat {input[1]} | awk '{{if ($2 > {params.min_size}) print $1}}' | xargs -n 1 -I foo sh -c "
			samtools faidx {input[0]} foo > {sample}/3.circularization/1.candidate_genomes/foo.fa
		"
		"""

rule circularize_bam2reads:
	input:
		rules.circularize_mapreads.output,
		"{sample}/3.circularization/1.candidate_genomes/{tig}.fa" #rules.extract_bigtigs.output
	output:
		"{sample}/3.circularization/2.circularization/spanning_tig_circularization/{tig}/{tig}_terminal_reads.fq.gz"
	singularity: singularity_image
	shell:
		"""
		(samtools idxstats {sample}/3.circularization/0.aligned_corrected.bam | grep {wildcards.tig} | awk '{{if ($2 > 50000) print $1, ":", $2-50000, "-", $2; else print $1, ":", 1, "-", $2 }}' | tr -d ' ';
		 samtools idxstats {sample}/3.circularization/0.aligned_corrected.bam | grep {wildcards.tig} | awk '{{if ($2 > 50000) print $1, ":", 1, "-", 50000; else print $1, ":", 1, "-", $2 }}' | tr -d ' ') |
		xargs -I foo sh -c 'samtools view -h {sample}/3.circularization/0.aligned_corrected.bam foo | samtools fastq - || true' | bgzip > {output}
		"""

rule circularize_assemble:
	input:
		rules.circularize_bam2reads.output
	output: "{sample}/3.circularization/2.circularization/spanning_tig_circularization/{tig}/{tig}.contigs.fasta"
	params:
		directory="{sample}/3.circularization/2.circularization/spanning_tig_circularization/{tig}",
	singularity: singularity_image if config['usegrid'] != 'True' and config['usegrid'] != True else '' #switch between image and local environment for canu depending on whether cluster execution is required
	resources:
		time=12,
		mem=50
	threads: 8
	shell:
		"""
		canu -useGrid=False -assemble -p {wildcards.tig} -d {params.directory}  \
		-nanopore-corrected {input} genomeSize=100000
		"""

		# """
		# canu -useGrid=False -assemble -p {params.prefix} -d {params.directory}  \
		# -nanopore-corrected {input} genomeSize=100000 gridOptions='{params.gridopts}' \
		# batMemory=128 batThreads=1
		# """

rule circularize_spantig_pre:
	input:
		"{sample}/3.circularization/1.candidate_genomes/{tig}.fa", #rules.extract_bigtigs.output
		rules.circularize_assemble.output,
		rules.circularize_assemble.output[0] + '.fai'
	output:
		"{sample}/3.circularization/2.circularization/spanning_tig_circularization/{tig}/potential_circularization_alignments.tsv"
	singularity: singularity_image
	params:
		directory = "{sample}/3.circularization/2.circularization/spanning_tig_circularization/{tig}",
		prefix="spanning_tigs_to_ref"
	threads: 4
	resources:
		time=4,
		mem=16
	shell:
		"""
		nucmer -t {threads} -b 5000 {input[0]} {input[1]} -p {params.directory}/{params.prefix}

		delta-filter -q {params.directory}/{params.prefix}.delta > {params.directory}/{params.prefix}.filt.delta

		show-coords -Tq {params.directory}/{params.prefix}.filt.delta | cut -f8,9 | sed '1,3d' | sort | \
		uniq -c | tr -s ' ' '\\t' | cut -f2-99 | grep -v ^1 | cut -f2,3 > {params.directory}/potential_circularizations.tsv || true

		show-coords -Tql {params.directory}/{params.prefix}.filt.delta | grep -f {params.directory}/potential_circularizations.tsv | cat > {output} || true
		"""

rule circularize_spantig:
	input: rules.circularize_spantig_pre.output
	output: "{sample}/3.circularization/2.circularization/spanning_tig_circularization/{tig}/contig_spanned.txt"
	params:
		margin=10000
	script:
		"scripts/spancircle.py"

rule circularize_span_trim:
	input:
		rules.circularize_spantig.output,
		rules.extract_bigtigs.output,
		rules.extract_bigtigs.output[0] + '.fai',
		rules.circularize_assemble.output,
		rules.circularize_assemble.output[0] + '.fai'
	output:
		"{sample}/3.circularization/3.circular_sequences/sh/{tig}_span_trim.sh"
	params:
		outfa = "{sample}/3.circularization/3.circular_sequences/{tig}_spanned.fa"
	run:
		span_out = open(input[0], 'r').readlines()
		cmd = ''
		if span_out == ['done\n'] or span_out[0].strip() == 'no circularizations': #no circularization occurred
			print('Nothing to do')
		else:
			trim = span_out[0].strip()
			trim_cmd = 'samtools faidx ' + input[1] + ' ' + trim + " > " + params.outfa + "\n"
			cmd += trim_cmd

			if len(span_out) == 3:
				extend = span_out[1].strip()
				extend_cmd = 'samtools faidx ' + input[3] + ' ' + extend + " | grep -v '>'" + " >> " + params.outfa + "\n"
	#			print(extend_cmd)
				cmd += extend_cmd

		open(output[0], 'w').write(cmd + '\n')

rule circularize_overcirc:
	input:
		"{sample}/3.circularization/1.candidate_genomes/{tig}.fa"
	output: "{sample}/3.circularization/2.circularization/overcircularized/overcirc_{tig}.txt"
	params:
		delta = '{sample}/3.circularization/2.circularization/overcircularized/{tig}.delta'
	threads: 8
	singularity: singularity_image
	script:
		"scripts/encircle.py"

rule circularize_overcirc_trim:
	input:
		rules.circularize_overcirc.output,
		rules.extract_bigtigs.output,
		rules.extract_bigtigs.output[0] + '.fai',
		rules.circularize_assemble.output,
		rules.circularize_assemble.output[0] + '.fai'
	output:
		"{sample}/3.circularization/3.circular_sequences/sh/{tig}_span_overcirc.sh"
	params:
		outfa = "{sample}/3.circularization/3.circular_sequences/{tig}_overcirc.fa"
	run:
		span_out = open(input[0], 'r').readlines()
		cmd = ''
		if span_out == ['done\n']: #no circularization occurred
			print('Nothing to do')
		else:
			trim = span_out[0].strip()
			trim_cmd = 'samtools faidx ' + input[1] + ' ' + trim + " > " + params.outfa + "\n"
			cmd += trim_cmd

		open(output[0], 'w').write(cmd + '\n')

rule circularize_final:
	input:
		rules.assemble_final.output,
		rules.assemble_final.output[0] + '.fai',
		dynamic(rules.circularize_overcirc_trim.output),
		dynamic(rules.circularize_span_trim.output)
	output:
		'{sample}/3.circularization/4.{sample}_circularized.fa'
	threads: 1
	shell:
		"""
		cat {sample}/3.circularization/3.circular_sequences/sh/* | bash
		ls {sample}/3.circularization/3.circular_sequences/ | grep .fa$ | cut -f1 -d '_' > circs.tmp || true
		(cat {input[1]} | grep -vf circs.tmp |
		cut -f1 | xargs samtools faidx {input[0]}; cat {sample}/3.circularization/3.circular_sequences/*.fa) |
		sed 's/\([ACTG]\)\\n/\1/g' | fold -w 120 > {output}
		#rm circs.tmp
		"""

rule final:
	input: skip_circularization_or_not()
	output: "{sample}/4.final/{sample}_final.fa"
	shell: "cp {input} {output}"
#Utility functions
#########################################################

rule align_paf:
	input:
		'{ref}.f{asta}',
		'{sample}/0.basecall/{sample}.fq'.format(sample = sample)
	output:
		"{ref}.f{asta}.paf"
	threads: 8
	singularity: singularity_image
	shell:
		"minimap2 -t {threads} -x map-ont {input} > {output}"

rule align_bam:
	input:
		'{ref}.f{asta}', #the asta bit makes this work for .fa and .fasta files
		'{sample}/0.basecall/{sample}.fq'.format(sample = sample)
	output:
		"{ref}.f{asta}.bam"
	threads: 16
	resources:
		time=6,
		mem=16
	singularity: singularity_image
	shell:
		"minimap2 -t {threads} -ax map-ont {input} | samtools sort --threads {threads} > {output}"

rule bam_idx:
	input:
		'{some}.bam'
	output:
		'{some}.bam.bai'
	singularity: singularity_image
	shell:
		"samtools index {input}"

rule faidx:
	input: '{something}.f{asta}'
	output: '{something}.f{asta}.fai'
	singularity: singularity_image
	shell: "samtools faidx {input}"
